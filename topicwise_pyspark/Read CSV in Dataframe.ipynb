{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d489ca60-4396-47de-a076-9cd1144c2db0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Basic CSV Read"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    \"/Volumes/bhushan_bronze_data/source_location/source_volume/amazon_sales_dataset.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef08114b-7d54-4c97-9c26-f92c9f67f716",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Schema Explicitly"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * \n",
    "\n",
    "path = \"/Volumes/bhushan_bronze_data/source_location/source_volume/amazon_sales_dataset.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"order_date\", StringType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"product_category\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True),\n",
    "    StructField(\"discount_percent\", IntegerType(), True),\n",
    "    StructField(\"quantity_sold\", IntegerType(), True),\n",
    "    StructField(\"customer_region\", StringType(), True),\n",
    "    StructField(\"payment_method\", StringType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "    StructField(\"review_count\", IntegerType(), True),\n",
    "    StructField(\"discounted_price\", DoubleType(), True),\n",
    "    StructField(\"total_revenue\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"nullValue\", \"NA\") \\\n",
    "    .option(\"mode\", \"Permissive\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(path)\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc796bad-36d8-463b-90b4-a924f98ae7b0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify Schema"
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3e8ba1e-32ad-42ae-a2aa-58a57437b364",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Convert Date Column"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, col\n",
    "\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"order_date\",\n",
    "    to_date(col(\"order_date\").cast(\"string\"), \"yyyy-MM-dd\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "645f3cbb-9fcb-4980-ae26-dea31120846c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4811ce47-22ae-444e-8112-c9b6a89678d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Read CSV in Dataframe",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
